# Repaso


```{r setup-poblacion, include=FALSE}
options(htmltools.dir.version = FALSE)
library(pacman)
p_load(broom, latex2exp, ggplot2, ggthemes, viridis, dplyr, magrittr, knitr, parallel)
library(ggplot2)
library(ggtext)

# Color institucional
red_pink <- "#e64173"

# Opciones globales de knitr
opts_chunk$set(
  comment = "#>",
  fig.align = "center",
  fig.height = 9,
  fig.width  = 7,
  fig.asp = 1,
 out.width = "75%",
  warning = FALSE,
  message = FALSE
)

# Temas ggplot auxiliares
theme_empty <- theme_bw() + theme(
  line          = element_blank(),
  rect          = element_blank(),
  strip.text    = element_blank(),
  axis.text     = element_blank(),
  plot.title = element_text(size = rel(1), face = "bold", margin = margin(0,0,15,0), hjust = 0),
  axis.title = element_text(size = rel(0.85), face = "bold"),
  plot.margin   = margin(0,0,-1,-1, unit = "lines"),
  legend.position = "none")



theme_simple <- theme_bw() + theme(
  line          = element_blank(),
  panel.grid    = element_blank(),
  rect          = element_blank(),
  strip.text    = element_blank(),
  axis.text.x   = element_text(size = 14),
  axis.text.y   = element_blank(),
  axis.ticks    = element_blank(),
  plot.title    = element_blank(),
  axis.title    = element_blank(),
  legend.position = "none"
)
```

### ¬øQu√© estudia la econometr√≠a? {-}

La econometr√≠a es la herramienta que usamos para entender el mundo usando datos. Nos ayuda a responder preguntas como: ¬øcu√°nto gana una persona seg√∫n su nivel educativo? ¬øC√≥mo influye la experiencia laboral en el salario? ¬øCu√°l es el impacto de una pol√≠tica p√∫blica sobre el empleo?

Pero aqu√≠ hay un reto importante: casi nunca podemos observar a toda la poblaci√≥n. En vez de eso, trabajamos con una muestra. Usamos esta muestra para hacer inferencias sobre c√≥mo funciona el mundo real, ese que no podemos ver completamente. En este cap√≠tulo vamos a entender, paso a paso, por qu√© eso genera incertidumbre ‚Äîy por qu√© esa incertidumbre es una parte inevitable (¬°y valiosa!) del an√°lisis econom√©trico.


### El proceso generador de datos {-}

Supongamos que el salario de un individuo, \(y_i\), depende de forma lineal de su nivel educativo, \(x_i\):

\[
y_i \;=\; \beta_0 \;+\; \beta_1\,x_i \;+\; u_i,
\]

donde \(u_i\) recoge todo lo que **no** observamos (habilidad, contactos, suerte‚Ä¶).  
A esta ecuaci√≥n la llamaremos **Proceso Generador de Datos (PGD)** o **modelo poblacional**. El problema es que no podemos observar \(u_i\) porque es un t√©rmino de error. Ni tenemos acceso a todos los individuos de la poblaci√≥n.

### ¬øQu√© hacemos entonces? {-}

En la pr√°ctica, tomamos una muestra aleatoria de individuos y observamos sus salarios y a√±os de educaci√≥n \((y_i,\,x_i)\), el termino de error \(u_i\) permanece oculto.

Con una muestra aleatoria de tama√±o \(n\), estimamos los par√°metros \(\beta_0\) y \(\beta_1\) de la siguiente manera:

\[
y_i \;=\; \hat{\beta}_0 + \hat{\beta}_1\,x_i + e_i,
\qquad
\hat{y}_i \;=\; \hat{\beta}_0 + \hat{\beta}_1\,x_i,
\]

Donde \(\hat{\beta}_0\) y \(\hat{\beta}_1\) son los estimadores de los par√°metros poblacionales \(\beta_0\) y \(\beta_1\), y \(e_i\) es el t√©rmino de error muestral. A la recta que obtenemos se le llama **modelo muestral**. La direfencia entre este modelo y el PGD es precisamente lo que genera incertidumbre en nuestras estimaciones. Es decir que tenemos dos fuentes de incertidumbre, la muestra que compone nuestros datos y el t√©rmino de error \(u_i\) que no podemos observar.

Para entender todo esto mejor, vamos primero a enfocarnos en la muestra que tenemos y c√≥mo podemos usarla para estimar el PGD. Luego veremos c√≥mo la incertidumbre afecta nuestras estimaciones y por qu√© es importante.

## Construimos una poblaci√≥n de juguete {-}

Para ilustrar el proceso generador de datos y la incertidumbre, vamos a crear una poblaci√≥n de juguete. Esta poblaci√≥n ser√° un conjunto de 100 individuos con caracter√≠sticas espec√≠ficas. Luego tomaremos muestras aleatorias de esta poblaci√≥n y realizaremos regresiones para ver c√≥mo se comportan nuestras estimaciones en comparaci√≥n con el PGD real.

Vamos a crear un mundo ficticio con 100 individuos. A cada uno le asignamos:

* $x$ (a√±os de educaci√≥n) sigue una normal con media¬†5 y desviaci√≥n¬†1.5.
* $y$ depende linealmente de $x$ con pendiente¬†0.5 y un t√©rmino aleatorio $u\sim N(0,1)$.


```{R, gen dataset, include = F, cache = T}
# Set population and sample sizes
n_p <- 100
n_s <- 30
# Set the seed
set.seed(12468)
# Generate data
pop_df <- tibble(
  i = 3,
  x = rnorm(n_p, mean = 5, sd = 1.5),
  e = rnorm(n_p, mean = 0, sd = 1),
  y = i + 0.5 * x + e,
  row = rep(1:sqrt(n_p), times = sqrt(n_p)),
  col = rep(1:sqrt(n_p), each = sqrt(n_p)),
  s1 = sample(x = c(rep(T, n_s), rep(F, n_p - n_s))),
  s2 = sample(x = c(rep(T, n_s), rep(F, n_p - n_s))),
  s3 = sample(x = c(rep(T, n_s), rep(F, n_p - n_s)))
)
# Regressions
lm0 <- lm(y ~ x, data = pop_df)
lm1 <- lm(y ~ x, data = filter(pop_df, s1 == T))
lm2 <- lm(y ~ x, data = filter(pop_df, s2 == T))
lm3 <- lm(y ~ x, data = filter(pop_df, s3 == T))
# Simulation
set.seed(12468)
sim_df <- mclapply(mc.cores = 10, X = 1:1e4, FUN = function(x, size = n_s) {
  lm(y ~ x, data = pop_df %>% sample_n(size = size)) %>% tidy()
}) %>% do.call(rbind, .) %>% as_tibble()
```


```{R, pop1, echo = F, fig.fullwidth = T, dev = "svg"}
ggplot(data = pop_df, aes(x = row, y = col)) +
geom_point(color = "darkslategray", size = 8) +
  labs(
    title = "Grafica 1. 100 Individuos",
    subtitle = "Ubicaci√≥n de cada individo"
  ) + theme_empty
```


### La relaci√≥n verdadera en la poblaci√≥n {-}
El modelo poblacional que usamos, es decir el PGD, es: $y = 3 + 0.5x$: As√≠ que en promedio los salarios de los individuos aumentan en 0.5 por cada a√±o adicional de educaci√≥n. Esta es la verdad de nuestra poblaci√≥n simulada. 

```{R, scatter1, echo = F, fig.fullwidth = T, dev = "svg"}
ggplot(data = pop_df, aes(x = x, y = y)) +
geom_abline(
  intercept = lm0$coefficients[1], slope = lm0$coefficients[2],
  color = red_pink, size = 3
) +
geom_point(color = "darkslategray", size = 6) + 
  labs(
    title = "Grafica 2. L√≠nea de regresi√≥n",
    subtitle = "Relaci√≥n verdadera"
  )+
theme_empty
```

Obtenemos que los coeficientes son muy similares a los que usamos para generar la poblaci√≥n: 

$$ y_i = `r round(lm0$coefficients[1], 2)` + `r round(lm0$coefficients[2], 2)` x_i + u_i $$
Esto significa que el modelo poblacional es:

$$ y_i = \beta_0 + \beta_1 x_i + u_i $$
Sin embargo, esa linea est√° fuera de nuestro alcance porque requerir√≠a encuestar a *todos* los egresados. Podemos estimar la relaci√≥n entre $y$ y $x$ en una muestra aleatoria de individuos. Comencemos tomando 30 graduados al azar de nuestro grupo de 100 individuos: 

```{R, sample1, echo = F, fig.fullwidth = T, dev = "svg"}
ggplot(data = pop_df, aes(x = row, y = col, shape = s1)) +
geom_point(color = "darkslategray", size = 10) +
scale_shape_manual(values = c(1, 19)) +
  labs(
    title = "Grafica 3. 30 individuos seleccionados al azar",
  )+
theme_empty
```

Estimemos la relaci√≥n que existe entre $y$ y $x$ en esta muestra de 30 individuos. En la siguiente gr√°fica, la l√≠nea roja es el modelo poblacional y la l√≠nea negra discontinua es el modelo muestral.

```{R, sample1 scatter, echo = F, fig.fullwidth = T, dev = "svg"}
ggplot(data = pop_df, aes(x = x, y = y)) +
geom_abline(
  intercept = lm0$coefficients[1], slope = lm0$coefficients[2],
  color = red_pink, size = 3, alpha = 0.3
) +
geom_point(aes(shape = s1), color = "darkslategray", size = 6) +
geom_abline(
  intercept = lm1$coefficients[1], slope = lm1$coefficients[2],
  size = 2, linetype = 2, color = "black"
) +
scale_shape_manual(values = c(1, 19))  + 
  labs(
    title = "Grafica 4. L√≠nea de regresi√≥n",
    subtitle = "Relaci√≥n Muestral"
  )+
theme_empty
```

Ahora encontramos unos coeficientes estimados que son diferentes a los del modelo poblacional:

**PGD Modelo Poblacional**
<br>
$y_i = `r round(lm0$coefficients[1], 2)` + `r round(lm0$coefficients[2], 2)` x_i + u_i$

**Modelo muestral**
<br>
$\hat{y}_i = `r round(lm1$coefficients[1], 2)` + `r round(lm1$coefficients[2], 2)` x_i$

Tomemos otros 30 individuos al azar de la poblaci√≥n y veamos c√≥mo se comporta la regresi√≥n. 

```{R, sample2, echo = F, fig.fullwidth = T, dev = "svg"}
ggplot(data = pop_df, aes(x = row, y = col, shape = s2)) +
geom_point(color = "darkslategray", size = 10) +
scale_shape_manual(values = c(1, 19)) +  
  labs(
    title = "Grafica 5. Otros 30 individuos al azar",
  )+
theme_empty
```

```{R, sample2 scatter, echo = F, fig.fullwidth = T, dev = "svg"}
ggplot(data = pop_df, aes(x = x, y = y)) +
geom_abline(
  intercept = lm0$coefficients[1], slope = lm0$coefficients[2],
  color = red_pink, size = 3, alpha = 0.3
) +
geom_point(aes(shape = s2), color = "darkslategray", size = 6) +
geom_abline(
  intercept = lm1$coefficients[1], slope = lm1$coefficients[2],
  size = 2, linetype = 2, color = "black", alpha = 0.3
) +
geom_abline(
  intercept = lm2$coefficients[1], slope = lm2$coefficients[2],
  size = 2, linetype = 2, color = "black"
) +
scale_shape_manual(values = c(1, 19)) +
theme_empty
```

Ahora encontramos los siguientes coeficientes estimados:

**PGD Modelo Poblacional**
<br>
$y_i = `r round(lm0$coefficients[1], 2)` + `r round(lm0$coefficients[2], 2)` x_i + u_i$

**Modelo muestral**
<br>
$\hat{y}_i = `r round(lm2$coefficients[1], 2)` + `r round(lm2$coefficients[2], 2)` x_i$

Podemos ver que los coeficientes estimados son diferentes a los del modelo poblacional y tambi√©n diferentes entre s√≠. Esto es normal, porque cada muestra aleatoria puede dar lugar a diferentes estimaciones.

Tomemos una tercera muestra aleatoria de 30 individuos y veamos c√≥mo se comporta la regresi√≥n.
```{R, sample3, echo = F, fig.fullwidth = T, dev = "svg"}
ggplot(data = pop_df, aes(x = row, y = col, shape = s3)) +
geom_point(color = "darkslategray", size = 10) +
scale_shape_manual(values = c(1, 19)) +
theme_empty
```
```{R, sample3 scatter, echo = F, fig.fullwidth = T, dev = "svg"}
ggplot(data = pop_df, aes(x = x, y = y)) +
geom_abline(
  intercept = lm0$coefficients[1], slope = lm0$coefficients[2],
  color = red_pink, size = 3, alpha = 0.3
) +
geom_point(aes(shape = s3), color = "darkslategray", size = 6) +
geom_abline(
  intercept = lm1$coefficients[1], slope = lm1$coefficients[2],
  size = 2, linetype = 2, color = "black", alpha = 0.3
) +
geom_abline(
  intercept = lm2$coefficients[1], slope = lm2$coefficients[2],
  size = 2, linetype = 2, color = "black", alpha = 0.3
) +
geom_abline(
  intercept = lm3$coefficients[1], slope = lm3$coefficients[2],
  size = 2, linetype = 2, color = "black"
) +
scale_shape_manual(values = c(1, 19)) +
theme_empty
```

Ahora encontramos los siguientes coeficientes estimados:

**PGD Modelo Poblacional**
<br>
$y_i = `r round(lm0$coefficients[1], 2)` + `r round(lm0$coefficients[2], 2)` x_i + u_i$

**Modelo muestral**
<br>
$\hat{y}_i = `r round(lm3$coefficients[1], 2)` + `r round(lm3$coefficients[2], 2)` x_i$

Siguen siendo diferentes a los del modelo poblacional y tambi√©n diferentes entre s√≠. A veces se parece mucho, a veces no tanto. La raz√≥n es simple; cada muestra incluye un conjunto diferente de personas y eso cambia los resultados.

Ahora repitamos esto **10,000 veces**. Este ejercicio se conoce como Ejercicio de Monte Carlo. Vamos a tomar 10,000 muestras aleatorias de 30 individuos de nuestra poblaci√≥n y estimar los coeficientes de regresi√≥n para cada muestra. Luego, graficaremos todas las l√≠neas de regresi√≥n obtenidas para ver c√≥mo se distribuyen en relaci√≥n con la l√≠nea poblacional.

¬øLo interesante? Aunque cada recta individual es distinta, en promedio todas convergen hacia la recta verdadera (la primera que estimamos). 

```{R, simulation scatter, echo = F, dev = "png", dpi = 300, cache = T}
# Reshape sim_df
line_df <- tibble(
  intercept = sim_df %>% filter(term != "x") %>% select(estimate) %>% unlist(),
  slope = sim_df %>% filter(term == "x") %>% select(estimate) %>% unlist()
)
ggplot() +
geom_abline(data = line_df, aes(intercept = intercept, slope = slope), alpha = 0.01) +
geom_point(data = pop_df, aes(x = x, y = y), size = 3, color = "darkslategray") +
geom_abline(
  intercept = lm0$coefficients[1], slope = lm0$coefficients[2],
  color = red_pink, size = 1.5
) +
theme_empty
```


En resumen, en **promedio** las l√≠neas de regresi√≥n se ajustan muy bien a la l√≠nea de la poblaci√≥n. Sin embargo, las **l√≠neas individuales** (muestras) pueden desviarse significativamente. Las diferencias entre las muestras individuales y la poblaci√≥n generan **incertidumbre** para el econometrista.

>üëâ Este resultado es tranquilizador: aunque nuestras estimaciones var√≠an de muestra a muestra, en promedio nos acercamos a la verdad. Esto es lo que se conoce como insesgamiento del estimador MCO.

Eso implica que cuando estimamos los coeficientes de regresi√≥n, no podemos estar seguros de que nuestros estimadores sean exactamente iguales a los par√°metros poblacionales. En cambio, obtenemos estimaciones que son **variables aleatorias**. En otras palabras,  $\hat{\beta}$ en s√≠ mismo es una variable aleatoria, dependiente de la muestra aleatoria. Cuando tomamos una muestra y realizamos una regresi√≥n, no sabemos si es una muestra 'buena' ( $\hat{\beta}$ est√° cerca de $\beta$) o una muestra 'mala' (nuestra muestra difiere significativamente de la poblaci√≥n).

Mantener un registro de esta incertidumbre es clave para el an√°lisis econom√©trico. Nos permite entender la precisi√≥n de nuestras estimaciones y c√≥mo podemos mejorar nuestro modelo. 


## ¬øY si mi muestra es mala? {-}

> ‚ùì **Pregunta del lector:**  
> ¬øQu√© pasa si me toca una muestra mala? ¬øC√≥mo lo s√©? ¬øSe puede hacer algo para reducir esa incertidumbre?

Una *muestra mala* es una muestra que, por puro azar, no representa bien a la poblaci√≥n. Esto puede pasar incluso si tomamos la muestra correctamente. En esos casos, los estimadores como $\hat{\beta}_1$ pueden estar lejos de su valor verdadero $\beta_1$, y nuestras conclusiones podr√≠an ser enga√±osas.

### ¬øC√≥mo saber si me toc√≥ una muestra mala? {-}

No podemos saberlo con certeza, porque no conocemos la verdad poblacional. Pero hay se√±ales que nos pueden alertar:

- **Errores est√°ndar grandes**: indican mucha variabilidad en la estimaci√≥n.
- **Intervalos de confianza anchos**: reflejan gran incertidumbre.
- **Signos o tama√±os inesperados en los coeficientes**: pueden deberse a una muestra no representativa.
- **Pruebas de diagn√≥stico del modelo**: pueden revelar si los supuestos no se cumplen (residuos no normales, heterocedasticidad, etc.).

### ¬øSe puede reducir la incertidumbre muestral? {-}

¬°S√≠! Estas son algunas estrategias comunes:

- **Aumentar el tama√±o de la muestra ($n$)**   
  Entre m√°s observaciones, m√°s cerca estar√° $\hat{\beta}$ de $\beta$ (por la ley de los grandes n√∫meros).

- **Mejorar el dise√±o muestral**  
  Muestreos estratificados, por conglomerados o con pesos pueden hacer las estimaciones m√°s precisas.

- **Controlar por variables relevantes**  
  Incluir m√°s covariables reduce la varianza al explicar mejor el comportamiento de $y$.

- **Usar estimadores eficientes o robustos**  
  Si hay heterocedasticidad, los errores est√°ndar robustos o el uso de m√©todos como MCO ponderado pueden mejorar la precisi√≥n.

---

### ‚úÖ La importancia de la fuente de los datos {-}

Una forma muy eficaz de minimizar el riesgo de una muestra sesgada es **usar datos de fuentes confiables y con buen dise√±o muestral**.

> Por ejemplo, confiar en los datos del **DANE** en Colombia o de institutos nacionales de estad√≠stica en otros pa√≠ses es una pr√°ctica fundamental.  
> Estas instituciones dise√±an cuidadosamente sus encuestas (como la ECH, ENUT o ENDS) para asegurar que sean **representativas de la poblaci√≥n**.  
> Si el muestreo est√° bien hecho desde el inicio, el margen de error se reduce y nuestras inferencias ser√°n mucho m√°s confiables.

---

> üí° **Mensaje clave:**  
> La incertidumbre **no es un error**: es una caracter√≠stica natural del trabajo con datos. Lo importante no es eliminarla, sino **medirla bien, comunicarla con claridad y tenerla en cuenta al tomar decisiones**.



## ¬øY si mantengo fija la muestra? {-}

Hasta ahora nos enfocamos en la incertidumbre que surge por el azar de la muestra. Ahora exploramos otra fuente igual de importante: la variabilidad del t√©rmino de error , incluso si la muestra es fija.

Hasta ahora vimos que la incertidumbre puede surgir del hecho de que trabajamos con una **muestra**: cada subconjunto aleatorio de la poblaci√≥n genera estimadores ligeramente diferentes.

Pero hay una **segunda fuente de incertidumbre**: el **t√©rmino de error \(u_i\)**.

### Recordemos el modelo: {-}

\[
y_i = \beta_0 + \beta_1 x_i + u_i
\]

Aunque tuvi√©ramos **toda la poblaci√≥n** (o una muestra perfecta), no podr√≠amos **predecir perfectamente \(y_i\)** porque el valor de \(u_i\) sigue siendo desconocido. 

El termino de error \(u_i\) representa **todo lo que influye en \(y_i\)** pero **no est√° capturado por \(x_i\)**. Por ejemplo, en un modelo donde \(y_i\) es el salario y \(x_i\) es la educaci√≥n:

- Habilidades intr√≠nsecas
- Redes de contacto
- Experiencia laboral previa
- Suerte (¬°s√≠, tambi√©n cuenta!)

Todo eso se concentra en \(u_i\), que es **no observable**, pero no irrelevante.
Incluso si estimamos \(\hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 x_i\) con una muestra fija:

- Nuestra **recta de regresi√≥n** capta la **tendencia promedio**.
- Pero los valores observados de \(y_i\) se **dispersan alrededor de la recta** por culpa de \(u_i\).

Esto se ve as√≠:

```{R, error_term, echo = F, dev = "svg", fig.height = 6}
ggplot(data = pop_df, aes(x = x, y = y)) +
geom_abline(
  intercept = lm0$coefficients[1], slope = lm0$coefficients[2],
  color = red_pink, size = 3, alpha = 0.3
) +
geom_point(aes(shape = s1), color = "darkslategray", size = 6) +
geom_abline(
  intercept = lm1$coefficients[1], slope = lm1$coefficients[2],
  size = 2, linetype = 2, color = "black"
) +
scale_shape_manual(values = c(1, 19)) +
  
  labs(
    title = "Grafica 6. Efecto del t√©rmino de error",
    subtitle = "Dispersi√≥n de los valores observados"
  ) +
  theme_empty
```


Al repetir el proceso de muestreo muchas veces, cada muestra tendr√° su propia recta de regresi√≥n, pero todas estar√°n **dispersas alrededor de la recta poblacional**. 

Vamos a hacer lo siguiente:

1. Tomamos **una sola muestra fija** de 30 individuos de la poblaci√≥n.
2. Mantenemos sus valores de \(x_i\) constantes.
3. Re-generamos el t√©rmino de error \(u_i \sim N(0,1)\) **varias veces**.
4. Calculamos nuevos valores de \(y_i = 3 + 0.5x_i + u_i\) en cada iteraci√≥n.
5. Estimamos una regresi√≥n para cada muestra simulada.

Esto nos permite ver c√≥mo **las estimaciones var√≠an** √∫nicamente por culpa del t√©rmino de error, manteniendo fija la muestra.

```{R, error_term_sim, echo = F, dev = "svg", fig.height = 6}
# tomemos una sola muestra fija
fixed_sample <- pop_df %>% filter(s1 == T)
# Re-generamos el t√©rmino de error y calculamos nuevos valores de y
set.seed(12468)
sim_df <- mclapply(mc.cores = 10, X = 1:1e4, FUN = function(x, fixed_sample) {
  fixed_sample$e <- rnorm(nrow(fixed_sample), mean = 0, sd = 1)
  fixed_sample$y <- fixed_sample$i + 0.5 * fixed_sample$x + fixed_sample$e
  lm(y ~ x, data = fixed_sample) %>% tidy()
}, fixed_sample = fixed_sample) %>% do.call(rbind, .) %>% as_tibble()
# Reshape sim_df
line_df <- tibble(
  intercept = sim_df %>% filter(term != "x") %>% select(estimate) %>% unlist(),
  slope = sim_df %>% filter(term == "x") %>% select(estimate) %>% unlist()
)
ggplot() +
geom_abline(data = line_df, aes(intercept = intercept, slope = slope), alpha = 0.01) +
geom_point(data = fixed_sample, aes(x = x, y = y), size = 3, color = "darkslategray") +
geom_abline(
  intercept = lm0$coefficients[1], slope = lm0$coefficients[2],
  color = red_pink, size = 1.5
) +
  labs(
    title = "Grafica 7. Efecto del t√©rmino de error",
    subtitle = "Variaci√≥n de las estimaciones por el t√©rmino de error"
  ) +
theme_empty

```
Aqu√≠ vemos que, aunque la muestra es fija, las rectas de regresi√≥n se dispersan alrededor de la recta poblacional. Esto es porque el t√©rmino de error \(u_i\) introduce variabilidad en los valores de \(y_i\).


### ‚òùÔ∏è Una aclaraci√≥n importante sobre el insesgamiento {-}

Al repetir el proceso de muestreo muchas veces, cada muestra tendr√° su propia recta de regresi√≥n. 

Pero **ojo**: aunque esas rectas se vean "alrededor" de la recta poblacional en nuestras simulaciones, **esto no siempre ocurre en la vida real**.

> **El hecho de que las estimaciones se agrupen alrededor de los verdaderos valores poblacionales depende de que se cumplan los supeustos de modelo de regresi√≥n lineal.**

Por ejemplo:

- Si el t√©rmino de error \(u_i\) **est√° correlacionado con \(x_i\)** (por ejemplo, porque omitimos una variable relevante), entonces **nuestro estimador de \(\beta_1\) estar√° sesgado**.
- Si hay errores de medici√≥n, mala especificaci√≥n del modelo o selecci√≥n no aleatoria, tambi√©n se viola el insesgamiento.

---

### üéØ ¬øCu√°ndo es cierto que nuestras estimaciones "se agrupan" alrededor del verdadero \(\beta_1\)?  {-}

Cuando se cumplen los **supuestos del modelo cl√°sico de regresi√≥n lineal**, en particular exogeneidad estricta o **independencia del t√©rmino de error \(u_i\)** respecto a las variables explicativas \(x_i\). En algunos libros se conoce como esperanza condicional igual cero:  
  \[
  \mathbb{E}[u_i \mid x_i] = 0
  \]


> üîÅ **Si este supuestos se cumplen**, entonces nuestro estimador de M√≠nimos Cuadrados Ordinarios (MCO) es **insesgado**:  
> \[
> \mathbb{E}[\hat{\beta}_1] = \beta_1
> \]

Es decir, **si repiti√©ramos el experimento de muestreo muchas veces**, el **promedio** de nuestras estimaciones converger√≠a al verdadero valor poblacional.

Pero si **no se cumplen**, como veremos m√°s adelante, podemos tener:

- Estimadores sesgados  
- Estimadores inconsistentes  
- Intervalos de confianza y pruebas de hip√≥tesis inv√°lidos

---

### üí¨ Entonces, ¬ølas simulaciones que hicimos son ‚Äúrealistas‚Äù?  {-}

S√≠... **bajo los supuestos del modelo cl√°sico**. En nuestras simulaciones controlamos todo: sabemos exactamente c√≥mo se genera \(y_i\), y aseguramos que \(u_i\) sea independiente de \(x_i\). Por eso nuestras estimaciones tienden a agruparse cerca de la recta poblacional.

Pero en el mundo real, los datos no vienen con etiqueta de ‚Äúsupuestos cumplidos‚Äù.

> Por eso uno de los grandes desaf√≠os del an√°lisis econom√©trico es **diagnosticar y justificar** si los supuestos se cumplen.  
> Y si no se cumplen, buscar soluciones: variables instrumentales, variables omitidas, dise√±os cuasiexperimentales, dise√±os experimentales, etc.


> üí° **Conclusi√≥n clave:**  
> El t√©rmino de error no desaparece, incluso cuando tenemos una muestra grande o bien dise√±ada.  
> Por eso, cualquier estimaci√≥n puntual (\( \hat{\beta}_1 \)) debe ir acompa√±ada de una **medida de incertidumbre**, como el **error est√°ndar** o un **intervalo de confianza**.  
> Esto nos prepara para el siguiente paso: la inferencia estad√≠stica.

## üìò Preguntas de repaso {-}

1. ¬øQu√© diferencia hay entre el modelo poblacional y el modelo muestral? ¬øCu√°l de los dos observamos y cu√°l inferimos?

2. ¬øPor qu√© decimos que el t√©rmino de error \(u_i\) es una fuente de incertidumbre, incluso si la muestra est√° fija?

3. ¬øQu√© condiciones deben cumplirse para que el estimador de M√≠nimos Cuadrados Ordinarios (MCO) sea insesgado?

4. ¬øQu√© significa que un estimador sea insesgado ‚Äúen promedio‚Äù? ¬øEso garantiza que cualquier muestra nos dar√° un buen resultado?

5. ¬øQu√© implicaciones tiene usar una muestra mal dise√±ada o no representativa?

6. En la simulaci√≥n Monte Carlo, ¬øpor qu√© las rectas de regresi√≥n estimadas con diferentes muestras se agrupan alrededor de la recta poblacional?

7. ¬øQu√© observas cuando repetimos la estimaci√≥n con una misma muestra, pero re-generamos el t√©rmino de error? ¬øQu√© se mantiene constante y qu√© var√≠a?

8. En tus propias palabras, ¬øpor qu√© no podemos predecir perfectamente \(y_i\) aunque conozcamos bien \(x_i\)?

9. ¬øPor qu√© se llama ‚ÄúMonte Carlo‚Äù a este m√©todo de simulaci√≥n? ¬øQu√© relaci√≥n tiene con el azar?


10. ¬øQu√© riesgos implica asumir que los supuestos del modelo cl√°sico se cumplen cuando en realidad no lo hacen?

11. ¬øQu√© estrategias puedes usar si sospechas que \(u_i\) est√° correlacionado con \(x_i\)? Menciona al menos dos.

12. ¬øCrees que todas las fuentes oficiales de datos (como el DANE) garantizan muestras perfectamente representativas? ¬øQu√© condiciones lo permitir√≠an?

---

> ‚úèÔ∏è *Opcional para pr√°ctica adicional:* simula tu propia poblaci√≥n de juguete con una relaci√≥n negativa entre \(x\) y \(y\), y repite el ejercicio de Monte Carlo. ¬øQu√© cambia? ¬øQu√© se mantiene?


::: {.callout-note title="üü¶ Simulaci√≥n Monte Carlo con muestra fija en R"}

```r
# Paso 1: Crear muestra fija de x
set.seed(123)
n <- 30
x <- rnorm(n, mean = 5, sd = 1.5)

# Paso 2: Definir n√∫mero de simulaciones
B <- 1000

# Paso 3: Simular y almacenar coeficientes
library(tibble)
library(purrr)
library(broom)

sim <- map_dfr(1:B, function(i) {
  u <- rnorm(n, 0, 1)
  y <- 3 + 0.5 * x + u
  model <- lm(y ~ x)
  tidy(model)[2, c("term", "estimate")]
})

# Paso 4: Visualizar distribuci√≥n del estimador
library(ggplot2)

ggplot(sim, aes(x = estimate)) +
  geom_histogram(bins = 40, fill = "steelblue", color = "white") +
  geom_vline(xintercept = 0.5, color = "red", linetype = "dashed") +
  labs(
    title = "Distribuci√≥n de \\(\\hat{\\beta}_1\\) con muestra fija",
    x = "Estimaciones de \\(\\hat{\\beta}_1\\)", y = "Frecuencia"
  )
```



---



::: {.callout-note title="üü¶ Simulaci√≥n Monte Carlo con muestra fija en Stata"}

```stata
clear all
set seed 123
set obs 30

* Paso 1: Crear muestra fija de x
gen x = rnormal(5, 1.5)

* Paso 2: Guardar la muestra base
tempfile base
save `base'

* Paso 3: Preparar almacenamiento de resultados
tempname resultados
postfile `resultados' b1 using results_sim.dta, replace

* Paso 4: Simulaci√≥n Monte Carlo
local reps = 1000
forvalues i = 1/`reps' {
    use `base', clear
    gen u = rnormal(0,1)
    gen y = 3 + 0.5*x + u
    regress y x
    post `resultados' (_b[x])
}

postclose `resultados'

* Paso 5: Usar y graficar los resultados
use results_sim.dta, clear
histogram b1, width(0.02) normal ///
    title("Distribuci√≥n de coeficientes con muestra fija") ///
    xtitle("Estimaciones de _b[x]") ytitle("Frecuencia")

```





